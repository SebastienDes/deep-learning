{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDFIA : Notebook Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "import numpy as np\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, keep_all=False):\n",
    "        self.reset()\n",
    "        self.data = None\n",
    "        if keep_all:\n",
    "            self.data = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if self.data is not None:\n",
    "            self.data.append(val)\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class TrainLossPlot(object):\n",
    "    def __init__(self):\n",
    "        self.loss_train = []\n",
    "        self.fig = plt.figure()\n",
    "\n",
    "    def update(self, loss_train):\n",
    "        self.loss_train.append(loss_train)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure(self.fig.number)\n",
    "        plt.clf()\n",
    "        plt.plot(np.array(self.loss_train))\n",
    "        plt.title(\"Train loss / batch\")\n",
    "        plt.xlabel(\"Batch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.show()\n",
    "        plt.draw_all()\n",
    "        plt.pause(1e-3)\n",
    "\n",
    "class AccLossPlot(object):\n",
    "    def __init__(self):\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.acc_train = []\n",
    "        self.acc_test = []\n",
    "        self.fig = plt.figure()\n",
    "\n",
    "    def update(self, loss_train, loss_test, acc_train, acc_test):\n",
    "        self.loss_train.append(loss_train)\n",
    "        self.loss_test.append(loss_test)\n",
    "        self.acc_train.append(acc_train)\n",
    "        self.acc_test.append(acc_test)\n",
    "        plt.figure(self.fig.number)\n",
    "        plt.clf()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(np.array(self.acc_train), label=\"acc. train\")\n",
    "        plt.plot(np.array(self.acc_test), label=\"acc. test\")\n",
    "        plt.title(\"Accuracy / epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(np.array(self.loss_train), label=\"loss train\")\n",
    "        plt.plot(np.array(self.loss_test), label=\"loss test\")\n",
    "        plt.title(\"Loss / epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.draw_all()\n",
    "        plt.pause(1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports et constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.svm import LinearSVC\n",
    "from numpy import linalg as LA\n",
    "\n",
    "torchvision.models.vgg.model_urls[\"vgg16\"] = \"http://webia.lip6.fr/~robert/cours/rdfia/vgg16-397923af.pth\"\n",
    "os.environ[\"TORCH_MODEL_ZOO\"] = \"/tmp/torch\"\n",
    "PRINT_INTERVAL = 50\n",
    "CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du dataset et compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size, path):\n",
    "    \"\"\"\n",
    "    Cette fonction charge le dataset et effectue des transformations sur chaqu\n",
    "    image (listées dans `transform=...`).\n",
    "    \"\"\"\n",
    "    train_dataset = datasets.ImageFolder(path+'/train',\n",
    "        transform=transforms.Compose([ transforms.Scale((224,224)),\n",
    "            transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(path+'/test',\n",
    "        transform=transforms.Compose([ transforms.Scale((224,224)),\n",
    "            transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                        batch_size=batch_size, shuffle=True, pin_memory=CUDA, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Différents modèles pré-entraînés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 jusqu'à ReLU 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16relu7(nn.Module):\n",
    "\n",
    "    def __init__(self, vgg16):\n",
    "\n",
    "        super(VGG16relu7, self).__init__()\n",
    "        #recopier toute la partie convolutionnelle\n",
    "        self.features = nn.Sequential( *list(vgg16.features.children()))\n",
    "        # garder une partie du classifieur, -2 pour s’arrêter à relu7\n",
    "        self.classifier = nn.Sequential( *list(vgg16.classifier.children())[:-2])\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 jusqu'à ReLU 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16relu5(nn.Module):\n",
    "\n",
    "    #whitout last maxPooling\n",
    "    # we can't add the vgg16.classifier cos it takes 25088 = 7*7*512\n",
    "    def __init__(self, vgg16):\n",
    "\n",
    "        super(VGG16relu5, self).__init__()\n",
    "        #recopier toute la partie convolutionnelle\n",
    "        self.features = nn.Sequential( *list(vgg16.features.children())[:-1])\n",
    "        # garder une partie du classifieur, -2 pour s’arrêter à relu7\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        return x\n",
    "    #size features in this case = 100352"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 jusqu'à ReLU 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16relu6(nn.Module):\n",
    "\n",
    "    #stop in the fist fc\n",
    "    def __init__(self, vgg16):\n",
    "\n",
    "        super(VGG16relu6, self).__init__()\n",
    "        #recopier toute la partie convolutionnelle\n",
    "        self.features = nn.Sequential( *list(vgg16.features.children()))\n",
    "        # garder une partie du classifieur, -2 pour s’arrêter à relu7\n",
    "        self.classifier = nn.Sequential( *list(vgg16.classifier.children())[:-5])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        x = self.classifier(x)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "\n",
    "    def __init__(self, alex):\n",
    "\n",
    "        super(Alexnet, self).__init__()\n",
    "        self.features = nn.Sequential( *list(alex.features.children()))\n",
    "        self.classifier = nn.Sequential( *list(alex.classifier.children())[:-1])\n",
    "    def forward(self, x):\n",
    "        print(x.size())\n",
    "        x = self.features(x)\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(x.size())\n",
    "        x = self.classifier(x)\n",
    "        print(x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG16 jusqu'à fc15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16fc15(nn.Module):\n",
    "\n",
    "    def __init__(self, vgg16):\n",
    "\n",
    "        super(VGG16fc15, self).__init__()\n",
    "        #recopier toute la partie convolutionnelle\n",
    "        self.features = nn.Sequential( *list(vgg16.features.children()))\n",
    "        # garder une partie du classifieur, -2 pour s’arrêter à relu7\n",
    "        newliste = list(vgg16.classifier.children())[:-1]\n",
    "        newliste.append(nn.Linear(4096, 15))\n",
    "        self.classifier = nn.Sequential( *newliste)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition d'une epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(data, model, criterion, optimizer=None):\n",
    "\n",
    "    model.eval() if optimizer is None else model.train()\n",
    "\n",
    "    # objets pour stocker les moyennes des metriques\n",
    "    avg_loss = AverageMeter()\n",
    "    avg_top1_acc = AverageMeter()\n",
    "    avg_top5_acc = AverageMeter()\n",
    "    avg_batch_time = AverageMeter()\n",
    "    global loss_plot\n",
    "\n",
    "    # on itere sur les batchs du dataset\n",
    "    tic = time.time()\n",
    "    for i, (input, target) in enumerate(data):\n",
    "\n",
    "        if CUDA: # si on fait du GPU, passage en CUDA\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        # forward\n",
    "        output = model(Variable(input))\n",
    "        \n",
    "        loss = criterion(output, Variable(target))\n",
    "\n",
    "        # backward si on est en \"train\"\n",
    "        if optimizer:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # calcul des metriques\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        batch_time = time.time() - tic\n",
    "        tic = time.time()\n",
    "\n",
    "        # mise a jour des moyennes\n",
    "        avg_loss.update(loss.data[0])\n",
    "        avg_top1_acc.update(prec1[0])\n",
    "        avg_top5_acc.update(prec5[0])\n",
    "        avg_batch_time.update(batch_time)\n",
    "        if optimizer:\n",
    "            loss_plot.update(avg_loss.val)\n",
    "\n",
    "        # affichage des infos\n",
    "        if i % PRINT_INTERVAL == 0:\n",
    "            print('[{0:s} Batch {1:03d}/{2:03d}]\\t'\n",
    "                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:5.1f} ({top1.avg:5.1f})\\t'\n",
    "                  'Prec@5 {top5.val:5.1f} ({top5.avg:5.1f})'.format(\n",
    "                   \"EVAL\" if optimizer is None else \"TRAIN\", i, len(data), batch_time=avg_batch_time, loss=avg_loss,\n",
    "                   top1=avg_top1_acc, top5=avg_top5_acc))\n",
    "            if optimizer:\n",
    "                loss_plot.plot()\n",
    "\n",
    "    # Affichage des infos sur l'epoch\n",
    "    print('\\n===============> Total time {batch_time:d}s\\t'\n",
    "          'Avg loss {loss.avg:.4f}\\t'\n",
    "          'Avg Prec@1 {top1.avg:5.2f} %\\t'\n",
    "          'Avg Prec@5 {top5.avg:5.2f} %\\n'.format(\n",
    "           batch_time=int(avg_batch_time.sum), loss=avg_loss,\n",
    "           top1=avg_top1_acc, top5=avg_top5_acc))\n",
    "\n",
    "    return avg_top1_acc, avg_top5_acc, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du VGG fc15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVGGfc(vgg16, train, test, max_Iter, step, CUDA=False):\n",
    "    \n",
    "    for p in vgg16.parameters():\n",
    "    \tp.requires_grad = False\n",
    "    model = VGG16fc15(vgg16)\n",
    "    if CUDA:\n",
    "        model.cuda()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD([p for p in model.parameters() if p.requires_grad], step)\n",
    "    # init plots\n",
    "    plot = AccLossPlot()\n",
    "    global loss_plot\n",
    "    loss_plot = TrainLossPlot()\n",
    "\n",
    "    # On itère sur les epochs\n",
    "    for i in range(max_Iter):\n",
    "        print(\"=================\\n=== EPOCH \"+str(i+1)+\" =====\\n=================\\n\")\n",
    "        # Phase de train\n",
    "        top1_acc, avg_top5_acc, loss = epoch(train, model, criterion, optimizer)\n",
    "        # Phase d'evaluation\n",
    "        top1_acc_test, top5_acc_test, loss_test = epoch(test, model, criterion)\n",
    "        # plot\n",
    "        plot.update(loss.avg, loss_test.avg, top1_acc.avg, top1_acc_test.avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction de features depuis les réseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, model):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, (input, target) in enumerate(data):\n",
    "        print(i)\n",
    "        if i % PRINT_INTERVAL == 0:\n",
    "            print('Batch {0:03d}/{1:03d}'.format(i, len(data)))\n",
    "        if CUDA:\n",
    "            input = Variable(input.type(torch.cuda.FloatTensor), \n",
    "                                             requires_grad=False)\n",
    "        else:\n",
    "            input = Variable(input.type(torch.FloatTensor), \n",
    "                                             requires_grad=False)\n",
    "        output = model(input).data.cpu().numpy()\n",
    "        #print(output.shape)\n",
    "        for o in range(len(output)):\n",
    "            norme = LA.norm(output[o])\n",
    "            X.append([float(i)/norme for i in output[o]])\n",
    "            y.append(target[o])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #print('Instanciation de VGG16')\n",
    "    #vgg16 = models.vgg16(pretrained=True)\n",
    "    #squeeznet = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "    alex = torchvision.models.alexnet(pretrained=True)\n",
    "    #print(*list(squeeznet.features.children()))\n",
    "    #print(*list(squeeznet.classifier.children()))\n",
    "   \n",
    "#    print('Instanciation de VGG16relu7')\n",
    "#    model = VGG16relu7(vgg16)\n",
    "#    model = VGG16relu5(vgg16)\n",
    "#   model.eval()\n",
    "    model = Alexnet(alex)\n",
    "#    model.eval()\n",
    "    #model.cuda()\n",
    "#    model = VGG16relu5(vgg16) \n",
    "        \n",
    "\n",
    "    #model.eval()\n",
    "    if CUDA: # si on fait du GPU, passage en CUDA\n",
    "        model = model.cuda()\n",
    "\n",
    "    # On récupère les données\n",
    "    print('Récupération des données')\n",
    "    train, test = get_dataset(BATCH_SIZE, PATH)\n",
    "#    if CUDA:\n",
    "#        cuda = True\n",
    "#    else:\n",
    "#        cuda = False\n",
    "#    trainVGGfc(vgg16,train, test ,100, 0.1, cuda)\n",
    "\n",
    "\n",
    "#     Extraction des features\n",
    "    print('Feature extraction')\n",
    "    X_train, y_train = extract_features(train, model)\n",
    "    X_test, y_test = extract_features(test, model)\n",
    "\n",
    "    # TODO Apprentissage et évaluation des SVM à faire\n",
    "    print('Apprentissage des SVM')\n",
    "    \n",
    "    #test for different C\n",
    "    acc = []\n",
    "    c = [0.1, 0.6, 1,  5, 10]\n",
    "    for value in c:\n",
    "        svm = LinearSVC(C=value)\n",
    "        svm.fit(X_train, y_train)\n",
    "        accuracy = svm.score(X_test, y_test)\n",
    "        print('C= ', value, 'accuracy= ', accuracy)\n",
    "        acc.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /tmp/torch\\alexnet-owt-4df8aa71.pth\n",
      "41.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "54.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "68.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "84.4%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Récupération des données\n",
      "Feature extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastien\\Anaconda3\\envs\\Deep Learning\\lib\\site-packages\\torchvision\\transforms\\transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  \"please use transforms.Resize instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Batch 000/012\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "1\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "2\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "3\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "4\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "5\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "6\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "7\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "8\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "9\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "10\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "11\n",
      "torch.Size([92, 3, 224, 224])\n",
      "torch.Size([92, 256, 6, 6])\n",
      "torch.Size([92, 9216])\n",
      "torch.Size([92, 4096])\n",
      "0\n",
      "Batch 000/024\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "1\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "2\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "3\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "4\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "5\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "6\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "7\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "8\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "9\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "10\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "11\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "12\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "13\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "14\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "15\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "16\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "17\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "18\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "19\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "20\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "21\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "22\n",
      "torch.Size([128, 3, 224, 224])\n",
      "torch.Size([128, 256, 6, 6])\n",
      "torch.Size([128, 9216])\n",
      "torch.Size([128, 4096])\n",
      "23\n",
      "torch.Size([41, 3, 224, 224])\n",
      "torch.Size([41, 256, 6, 6])\n",
      "torch.Size([41, 9216])\n",
      "torch.Size([41, 4096])\n",
      "Apprentissage des SVM\n",
      "C=  0.1 accuracy=  0.8361809045226131\n",
      "C=  0.6 accuracy=  0.8479061976549414\n",
      "C=  1 accuracy=  0.8455611390284757\n",
      "C=  5 accuracy=  0.8371859296482412\n",
      "C=  10 accuracy=  0.8341708542713567\n"
     ]
    }
   ],
   "source": [
    "# Paramètres en ligne de commande\n",
    "parser = argparse.ArgumentParser()\n",
    "BATCH_SIZE = 128\n",
    "PATH = \"15SceneData\"\n",
    "CUDA = True\n",
    "cudnn.benchmark = True\n",
    "\n",
    "main()\n",
    "\n",
    "input(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
